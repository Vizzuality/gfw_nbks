{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Iportable Globals and Metadata\n",
    "\n",
    "Global data and helper functions to be imported into each notebook.\n",
    "\n",
    "The functions here are outlined more clearly in 1.Globals_and_Metadata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:11:17.673011Z",
     "start_time": "2017-12-18T15:11:16.497985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "requests_cache.install_cache('demo_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:11:17.681268Z",
     "start_time": "2017-12-18T15:11:17.677095Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = '499682b1-3174-493f-ba1a-368b4636708e'  # ADMIN 2 level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='s0'></a>\n",
    "# Obtain metadata for admin-0 to admin-2 level\n",
    "\n",
    "Retrieve json mappings of id values (e.g. iso codes or integers) for admin0 to admin2 level, and map them to english names for selectors and resources to build dynamic sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:11:17.802395Z",
     "start_time": "2017-12-18T15:11:17.764016Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_admin0_json(urlCarto=\"https://wri-01.carto.com/api/v2/sql\"):\n",
    "    \"\"\"return an alphabetical json of mappings of iso and country names\n",
    "    e.g.\n",
    "    [{'iso': 'AFG', 'name': 'Afghanistan'},\n",
    "     {'iso': 'XAD', 'name': 'Akrotiri and Dhekelia'},\n",
    "     {'iso': 'ALA', 'name': 'Ã…land'},\n",
    "     ...\n",
    "    ]\n",
    "    \n",
    "    \"\"\"\n",
    "    sql = (\"SELECT iso, country as name FROM umd_nat_staging \"\n",
    "            \"GROUP BY iso, name \"\n",
    "            \"ORDER BY name \"\n",
    "          )\n",
    "    r = requests.get(urlCarto, params={\"q\": sql})\n",
    "    return r.json().get('rows', None)\n",
    " \n",
    "\n",
    "def get_admin1_json(iso, urlCarto=\"https://wri-01.carto.com/api/v2/sql\"):\n",
    "    \"\"\"return an alphabetical json of mappings of admin1 for a country\n",
    "    e.g. for iso='GBR'\n",
    "        [{'adm1': 1, 'name': 'England'},\n",
    "         {'adm1': 2, 'name': 'Northern Ireland'},\n",
    "         {'adm1': 3, 'name': 'Scotland'},\n",
    "         {'adm1': 4, 'name': 'Wales'}]\n",
    "    \"\"\"\n",
    "    sql = (\"SELECT id1 as adm1, region as name \"\n",
    "            \"FROM umd_subnat_staging \"\n",
    "            f\"WHERE iso = '{iso}' \"\n",
    "            \"and year = 2001 \"\n",
    "            \"and thresh = 30 \"\n",
    "            \"ORDER BY name \"\n",
    "          )\n",
    "    r = requests.get(urlCarto, params={\"q\": sql})\n",
    "    return r.json().get('rows', None)\n",
    "   \n",
    "\n",
    "def get_admin2_json(iso, adm1, urlCarto=\"https://wri-01.carto.com/api/v2/sql\"):\n",
    "    \"\"\" \n",
    "    e.g. response for iso='GBR' adm1=1\n",
    "    [{'adm2': 1, 'name': 'Barking and Dagenham'},\n",
    "     {'adm2': 2, 'name': 'Bath and North East Somerset'},\n",
    "     ...\n",
    "     ]\n",
    "\n",
    "    \"\"\"\n",
    "    sql = (\"SELECT id_2 as adm2, name_2 as name \"\n",
    "            \"FROM gadm28_adm2 \"\n",
    "            f\"WHERE iso = '{iso}' \"\n",
    "            f\"AND id_1 = {adm1} \"\n",
    "            \"ORDER BY name \"\n",
    "          )\n",
    "    r = requests.get(urlCarto, params={\"q\": sql})    \n",
    "    return r.json().get('rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:11:17.827573Z",
     "start_time": "2017-12-18T15:11:17.805779Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = get_admin0_json()\n",
    "iso_to_countries = {}\n",
    "for row in tmp:\n",
    "    iso_to_countries[row.get('iso')] = row.get('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info on an areas shape\n",
    "\n",
    "Use the Geostore service to find the geometry, bounding box or additional info on a given `iso` or `iso/admin1` area if required (e.g. for centering the map).\n",
    "\n",
    "Note - if similar info is needed for admin2 areas I will have to go back and create a query based on a Carto table, as admin-2 level data does not exist in the geostore service yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:11:17.885517Z",
     "start_time": "2017-12-18T15:11:17.831435Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iso = \"GBR\"\n",
    "adm1 = None \n",
    "\n",
    "if not adm1:\n",
    "    url = f\"https://api.resourcewatch.org/v1/geostore/admin/{iso}\"\n",
    "else:\n",
    "    url = f\"https://api.resourcewatch.org/v1/geostore/admin/{iso}/{adm1}\"\n",
    "    \n",
    "r = requests.get(url)\n",
    "\n",
    "roi = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T15:11:17.895130Z",
     "start_time": "2017-12-18T15:11:17.889581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bounding_poly(bbox):\n",
    "    \"\"\"Create a bounding polygon from a returned bbox of the geostore service\n",
    "        (- the old api produced shapes in this format).\n",
    "    \"\"\"\n",
    "    lat1, lon1, lat2, lon2  = bbox\n",
    "    return [[lat1,lon1], [lat1,lon2],[lat2,lon2],[lat2,lon1] ,[lat1,lon1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up global (scope) data sources for the Country Widgets \n",
    "\n",
    "There is some work that needs to be done in populating the Location menu, not all options should be always available: some of them will need to be iso dependent. E.g. `Biomes` should only appear in the menu if the ISO is set to `BRA`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-18T17:05:09.096857Z",
     "start_time": "2017-12-18T17:05:09.072707Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polynames = {\n",
    "                'All Region':'gadm28',\n",
    "                'Biomes':'bra_biomes',\n",
    "                'Mining':'mining',\n",
    "                'Protected Areas':'wdpa',\n",
    "                'Primary Forests':'primary_forest',\n",
    "                'Mining in Primary Forests':'primary_forest__mining',\n",
    "                'Protected Areas in Primary Forests':'primary_forest__wdpa',\n",
    "                'Intact Forest Landscapes':'ifl_2013',\n",
    "                'Protected Areas in Intact Forest Landscapes':'ifl_2013__wdpa',\n",
    "                'Mining in Intact Forest Landscapes':'ifl_2013__mining',\n",
    "                'Indigenous Lands':'landmark',\n",
    "                'Indigenous Lands in Primary Forests':'primary_forest__landmark',\n",
    "                'Plantations':'plantations',\n",
    "                'Mining in Plantation Areas':'plantations__mining',\n",
    "                'Protected areas in Plantations':'plantations__wdpa',\n",
    "                'Indigenous Lands in Plantations':'plantations__landmark',\n",
    "            }\n",
    "\n",
    "plantation_type_dict = {\n",
    "    \n",
    "                         'Large industrial plantation': 'large industrial',\n",
    "                         'Clearing/ very young plantation': 'clearing or very young',\n",
    "                         'Mosaic of medium-sized plantations': 'medium-sized',\n",
    "                         'Mosaic of small-sized plantations': 'small sized'\n",
    "\n",
    "                        }\n",
    "\n",
    "plantation_species_dict = {\n",
    "                            'Wood fiber / timber': 'wood fiber and timber',\n",
    "                            'Wood fiber / timber mix': 'mixed wood fiber and timber',\n",
    "                            'Recently cleared': 'recently cleared',\n",
    "                            'Unknown': 'unknown',\n",
    "                            'Fruit': 'fruit tree',\n",
    "                            'Fruit mix': 'mixed fruit tree',\n",
    "                            'Oil palm': 'palm tree',\n",
    "                            'Other mix': 'mixed',\n",
    "                            'Other': 'other',\n",
    "                            'Rubber': 'rubber tree'\n",
    "                            }\n",
    "\n",
    "extent_year_dict = {\n",
    "    \n",
    "         2000:'area_extent_2000',\n",
    "         2010:'area_extent'\n",
    "\n",
    "        }\n",
    "\n",
    "tabs = {\n",
    "         \"summary\":\"Summary\",\n",
    "         \"land_cover\":\"Land Cover\",\n",
    "         \"land_use\": \"Land Use\",\n",
    "         \"forest_change\": \"Forest Change\",\n",
    "         \"conservation\":'Conservation',\n",
    "         \"people\":\"People\",\n",
    "         \"climate\":\"Climate\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Whitelists Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iso = \"SAU\"\n",
    "adm1 = None\n",
    "adm2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_whitelist(iso, adm1=None, adm2=None):\n",
    "    if adm2:\n",
    "        sql = (f\"SELECT polyname FROM {ds} \"\n",
    "               \"WHERE thresh = 0 AND polyname is not 'gadm28' \"\n",
    "               f\"AND iso = '{iso}' AND adm1={adm1} AND adm2={adm2} \"\n",
    "               \"GROUP BY polyname\")\n",
    "    elif adm1:\n",
    "        sql = (f\"SELECT polyname FROM {ds} \"\n",
    "               \"WHERE thresh = 0 AND polyname is not 'gadm28' \"\n",
    "               f\"AND iso = '{iso}' AND adm1={adm1} \"\n",
    "               \"GROUP BY polyname\")\n",
    "    else:\n",
    "        sql = (f\"SELECT polyname FROM {ds} \"\n",
    "               \"WHERE thresh = 0 AND polyname is not 'gadm28' \"\n",
    "               f\"AND iso = '{iso}' \"\n",
    "               \"GROUP BY polyname\")\n",
    "    return sql\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create whitelist for each polyname\n",
    "\n",
    "url = f\"https://production-api.globalforestwatch.org/v1/query/{ds}\"\n",
    "sql = get_whitelist(iso=iso, adm1=adm1, adm2=adm2)\n",
    "\n",
    "properties = {\"sql\": sql}\n",
    "r = requests.get(url, params = properties)\n",
    "data = r.json().get('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_polys = []\n",
    "\n",
    "for d in data:\n",
    "    if d.get('polyname') not in unique_polys:\n",
    "        unique_polys.append(d.get('polyname'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create general Whitelist for each polyname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create whitelist for each polyname\n",
    "\n",
    "url = f\"https://production-api.globalforestwatch.org/v1/query/{ds}\"\n",
    "sql = (f\"SELECT iso, polyname FROM {ds} WHERE thresh = 0 AND polyname is not 'gadm28'\")\n",
    "\n",
    "properties = {\"sql\": sql}\n",
    "r = requests.get(url, params = properties)\n",
    "\n",
    "data = r.json().get('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist_by_polys = []\n",
    "\n",
    "for d in data:\n",
    "    if d.get('polyname') not in whitelist_by_polys:\n",
    "        whitelist_by_polys.append(d.get('polyname'))\n",
    "\n",
    "        \n",
    "polyname_config = {}\n",
    "for u in whitelist_by_polys:\n",
    "    tmp_isos = []\n",
    "    for d in data:\n",
    "        if d.get('polyname') == u and d.get('iso') not in tmp_isos:\n",
    "            tmp_isos.append(d.get('iso'))\n",
    "    polyname_config[u] = tmp_isos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Alternate Whitelist\n",
    "\n",
    "This query can be used to in place of the previous one to assess whether polynames contain non-zero data in addition to building a whitelist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iso = \"BRA\"\n",
    "adm1 = 4\n",
    "adm2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_alt_whitelist(iso, adm1=None, adm2=None):\n",
    "    if adm2:\n",
    "        sql = (\"SELECT polyname, SUM(area_extent_2000) as total_extent_2000, \"\n",
    "               \"SUM(area_extent) as total_extent_2010, \"\n",
    "               \"SUM(area_gain) as total_gain, \"\n",
    "               f\"SUM(year_data.area_loss) as total_loss FROM {ds} \"\n",
    "               \"WHERE thresh = 0 \"\n",
    "               f\"AND iso = '{iso}' AND adm1={adm1} AND adm2={adm2} \"\n",
    "               \"GROUP BY polyname\")\n",
    "    elif adm1:\n",
    "        sql = (\"SELECT polyname, SUM(area_extent_2000) as total_extent_2000, \"\n",
    "               \"SUM(area_extent) as total_extent_2010, \"\n",
    "               \"SUM(area_gain) as total_gain, \"\n",
    "               f\"SUM(year_data.area_loss) as total_loss FROM {ds} \"\n",
    "               \"WHERE thresh = 0 \"\n",
    "               f\"AND iso = '{iso}' AND adm1={adm1} \"\n",
    "               \"GROUP BY polyname\")\n",
    "    else:\n",
    "        sql = (\"SELECT polyname, SUM(area_extent_2000) as total_extent_2000, \"\n",
    "               \"SUM(area_extent) as total_extent_2010, \"\n",
    "               \"SUM(area_gain) as total_gain, \"\n",
    "               f\"SUM(year_data.area_loss) as total_loss FROM {ds} \"\n",
    "               \"WHERE thresh = 0 \"\n",
    "               f\"AND iso = '{iso}' \"\n",
    "               \"GROUP BY polyname\")\n",
    "    return sql\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create whitelist for each polyname\n",
    "\n",
    "url = f\"https://production-api.globalforestwatch.org/v1/query/{ds}\"\n",
    "sql = get_alt_whitelist(iso=iso, adm1=adm1, adm2=adm2)\n",
    "\n",
    "properties = {\"sql\": sql}\n",
    "r = requests.get(url, params = properties)\n",
    "\n",
    "data = r.json().get('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
